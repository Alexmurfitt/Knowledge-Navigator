Perfecto. He revisado los **7 documentos PDF completos** que forman tu base documental y ya puedo ayudarte con lo que necesitas.

---

## âœ… PROPUESTA INICIAL DE PREGUNTAS DE EVALUACIÃ“N RAG

Estas preguntas estÃ¡n especÃ­ficamente formuladas para:

* Ser respondidas **de forma clara y localizada** dentro de los documentos.
* Evaluar la capacidad del sistema RAG para:

  * Recuperar contenido preciso
  * Citar correctamente fuentes y pÃ¡ginas
  * Evitar alucinaciones
  * Mostrar comprensiÃ³n semÃ¡ntica

---

### ğŸ“„ Documento 1: *Framework for the Ethical Use of Advanced Data Science*

1. **Â¿CuÃ¡l es el objetivo principal del marco propuesto por el DSEG para el uso Ã©tico de la ciencia de datos en contextos humanitarios?**
2. **Â¿QuÃ© principios Ã©ticos generales se aplican especÃ­ficamente a los proyectos humanitarios con datos?**
3. **Â¿QuÃ© problemas plantea la falta de estÃ¡ndares cruzados en el uso de la ciencia de datos en el sector humanitario?**

---

### ğŸ“„ Documento 2: *Governing AI â€“ Upholding Human Rights (Data & Society)*

4. **Â¿CÃ³mo puede el enfoque de derechos humanos guiar el desarrollo y la gobernanza de la inteligencia artificial?**
5. **Â¿QuÃ© cinco derechos humanos se ven mÃ¡s afectados por los sistemas de IA, segÃºn el informe?**
6. **Â¿CuÃ¡l fue el rol de Facebook en el caso de Myanmar y quÃ© implicaciones tiene para los derechos humanos?**
7. **Â¿QuÃ© recomienda el informe en cuanto a evaluaciones de impacto en derechos humanos (HRIAs)?**

---

### ğŸ“„ Documento 3: *AI and Human Society â€“ JapÃ³n*

8. **Â¿CuÃ¡l es la posiciÃ³n del gobierno japonÃ©s respecto al equilibrio entre innovaciÃ³n en IA y principios Ã©ticos?**
9. **Â¿QuÃ© desafÃ­os Ã©ticos se identifican en el uso de IA en la sociedad japonesa?**

---

### ğŸ“„ Documento 4: *Tech Ethics Best Practices â€“ Markkula Center*

10. **Â¿QuÃ© recomienda el Markkula Center para asegurar una IA Ã©tica y centrada en el ser humano?**
11. **Â¿CuÃ¡les son los cinco valores fundamentales que debe cumplir un sistema de IA, segÃºn este documento?**

---

### ğŸ“„ Documento 5: *Gobernanza algorÃ­tmica y auditorÃ­a de sesgo â€“ Bustelo*

12. **Â¿QuÃ© se entiende por â€œauditorÃ­a algorÃ­tmicaâ€ y quÃ© desafÃ­os presenta su implementaciÃ³n?**
13. **Â¿QuÃ© propone el documento para mitigar los sesgos algorÃ­tmicos en sistemas de decisiÃ³n automatizada?**

---

### ğŸ“„ Documento 6: *IA y Derecho de DaÃ±os â€“ Berenguer et al.*

14. **Â¿QuÃ© riesgos plantea el uso de IA desde la perspectiva del derecho de daÃ±os?**
15. **Â¿QuÃ© tipos de responsabilidad jurÃ­dica se podrÃ­an aplicar en casos de perjuicios causados por sistemas de IA?**

---

### ğŸ“„ Documento 7: *IA y Transparencia AlgorÃ­tmica â€“ G. Vestri*

16. **Â¿QuÃ© elementos deben garantizarse para que un sistema de IA sea considerado transparente?**
17. **Â¿CÃ³mo se define la opacidad algorÃ­tmica en este documento y quÃ© consecuencias conlleva?**

---

## ğŸ“Š Siguientes pasos sugeridos

| Paso | AcciÃ³n                                                                                    |
| ---- | ----------------------------------------------------------------------------------------- |
| âœ… 1  | Validar que el sistema puede responder estas preguntas con precisiÃ³n y fuentes trazables. |
| ğŸ” 2 | Ajustar `k`, embeddings o prompts si alguna respuesta es deficiente.                      |
| ğŸ§ª 3 | Evaluar automÃ¡ticamente con RAGAS usando estas preguntas como **ground truth**.           |
| ğŸ§  4 | Incorporar resultados al diseÃ±o del agente de fusiÃ³n semÃ¡ntica.                           |

