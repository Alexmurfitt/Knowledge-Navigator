✅ 1. A Framework for the Ethical Use of Advanced Data Science
Guía ética para usar IA en el sector humanitario. Enfoca en: privacidad, sesgo, derechos humanos, y rendición de cuentas. Incluye ciclo de vida del proyecto y casos de uso como NLP y modelos predictivos.


✅ 2. Governing AI: Upholding Human Rights (Data & Society)
Marco basado en derechos humanos para gobernar la IA. Analiza riesgos en privacidad, igualdad, expresión, participación y discapacidad. Propone HRIAs y acción coordinada entre gobiernos, empresas y ONGs.


✅ 3. AI and Human Society – Japón
Informe multiactor. Clasifica impactos de la IA en 6 ejes: ético, legal, económico, educativo, social y de I+D. Propone gobernanza colaborativa y uso seguro en sectores clave.


✅ 4. Tech Ethics Best Practices – Markkula Center
16 normas prácticas para aplicar ética en tecnología. Claves: evitar “ética de cumplimiento”, prever impactos, fomentar transparencia, responsabilidad y privacidad desde el diseño.


✅ 5. Gobernanza algorítmica y auditoría de sesgo (Bustelo)
Propuesta académica de gobernanza transparente. Foco en auditorías de sesgo, AI Act europeo, decisiones públicas automatizadas y necesidad de control institucional robusto.


✅ 6. IA y Derecho de Daños (Berenguer et al.)
Libro legal sobre responsabilidad civil por IA. Casos en salud, deepfakes, movilidad. Claves: discriminación algorítmica, explicabilidad, Reglamento IA 2024, RGPD.


✅ 7. IA y Transparencia Algorítmica – G. Vestri
Análisis jurídico de IA en la Administración pública. Propone diferenciar tipos de algoritmos y su impacto legal. Destaca la necesidad de transparencia y control humano en decisiones automatizadas.