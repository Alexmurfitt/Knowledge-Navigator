# âœ… FUSIÃ“N COMPLETA â€“ Knowledge Navigator con RAG + Razonamiento + BÃºsqueda Web

import streamlit as st
from langchain.memory import ConversationBufferMemory
from langchain.schema import HumanMessage, AIMessage
from langchain_google_community import GoogleSearchAPIWrapper
from ask_pdf_qdrant_mongodb_limpio import responder  # Sistema RAG + razonamiento hÃ­brido
from detectar_similitud import detectar_redundancia
from dotenv import load_dotenv
import os
import sys

# Permitir imports desde carpetas superiores
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
load_dotenv()

# --- ğŸ” Claves de entorno ---
google_api_key = os.getenv("GOOGLE_API_KEY")
google_cse_id = os.getenv("GOOGLE_CSE_ID")

# --- ğŸŒ Herramienta de bÃºsqueda web ---
search_tool = GoogleSearchAPIWrapper(
    google_api_key=google_api_key,
    google_cse_id=google_cse_id
)

# --- ğŸ’¾ Memoria de conversaciÃ³n y fuentes ---
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
if "source_documents" not in st.session_state:
    st.session_state.source_documents = []
if "adicionales" not in st.session_state:
    st.session_state.adicionales = []

# --- ğŸ¤– FunciÃ³n de respuesta principal ---
def obtener_respuesta(pregunta_usuario: str):
    advertencia = detectar_redundancia(pregunta_usuario)

    try:
        # Paso 1: RAG con razonamiento estructurado + CoT
        respuesta, adicionales, fuentes = responder(pregunta_usuario)

        # Paso 2: Si no hay resultados Ãºtiles, buscar en la web
        if "No tengo informaciÃ³n" in respuesta:
            st.info("No se encontrÃ³ informaciÃ³n en la base interna. Buscando en Internet...")
            resultados_web = search_tool.run(pregunta_usuario)

            # Prompt para Internet
            prompt_internet = f"""
Eres un asistente de IA especializado en ayudar con dudas sobre documentaciÃ³n empresarial.

BasÃ¡ndote en los siguientes resultados de bÃºsqueda en Internet, responde de forma clara, Ãºtil y precisa:

Resultados:
\"{resultados_web}\"

Pregunta del usuario:
\"{pregunta_usuario}\"

Respuesta final:
"""
            from langchain_ollama import ChatOllama
            modelo = ChatOllama(model="llama3", temperature=0.2)
            respuesta = modelo.invoke(prompt_internet).content

            st.session_state.source_documents = []
            st.session_state.adicionales = []
        else:
            # Guardar fuentes y adicionales en sesiÃ³n
            st.session_state.source_documents = fuentes
            st.session_state.adicionales = adicionales

            # ğŸ‘‰ Mostrar en consola
            if fuentes:
                print("\nğŸ“š DOCUMENTOS CONSULTADOS:")
                for i, doc in enumerate(fuentes):
                    nombre = doc.metadata.get("source", "desconocido")
                    pagina = doc.metadata.get("page", "N/A")
                    print(f"  {i+1}. {nombre} (p. {pagina})")

            if adicionales:
                print("\nğŸ”¸ INFORMACIÃ“N ADICIONAL:")
                for frase in adicionales:
                    print(f"â€¢ {frase}")

        # Guardar historial conversacional
        st.session_state.memory.save_context({"input": pregunta_usuario}, {"output": respuesta})
        return respuesta, advertencia

    except Exception as e:
        return f"âŒ Error durante la generaciÃ³n de la respuesta: {str(e)}", None

# --- ğŸ–¥ï¸ Interfaz visual ---
st.title("Knowledge Navigator")
st.caption("Sistema hÃ­brido con recuperaciÃ³n de documentos, razonamiento y bÃºsqueda en Internet")

# Mostrar historial de conversaciÃ³n
for msg in st.session_state.memory.chat_memory.messages:
    rol = "user" if isinstance(msg, HumanMessage) else "assistant"
    st.chat_message(rol).write(msg.content)

# Captura de nueva pregunta
if prompt := st.chat_input("Â¿En quÃ© puedo ayudarte hoy?"):
    st.chat_message("user").write(prompt)
    with st.spinner("Generando respuesta..."):
        respuesta_texto, advertencia = obtener_respuesta(prompt)

    if advertencia:
        st.warning(advertencia)

    st.chat_message("assistant").write(respuesta_texto)

    # Mostrar informaciÃ³n adicional (frases extra del razonador)
    if st.session_state.adicionales:
        with st.expander("ğŸ”¸ InformaciÃ³n adicional generada por el sistema"):
            for frase in st.session_state.adicionales:
                st.markdown(f"- {frase}")

    # Mostrar fuentes utilizadas
    with st.expander("ğŸ“š Fuentes de datos consultadas"):
        if st.session_state.source_documents:
            for doc in st.session_state.source_documents:
                if isinstance(doc, str):
                    st.info(doc)
                else:
                    nombre = doc.metadata.get("source", "desconocido")
                    pagina = doc.metadata.get("page", "N/A")
                    st.info(f"{nombre} (p. {pagina})")
        else:
            st.info("No se utilizaron fuentes documentales internas.")
