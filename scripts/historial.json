[
  {
    "pregunta": "Â¿QuÃ© elementos deben garantizarse para que un sistema de IA sea considerado transparente?",
    "pregunta_refinada": "Â¿CuÃ¡les son los elementos clave que deben estar presentes en un sistema de IA para garantizar su transparencia, es decir, para que los usuarios puedan comprender cÃ³mo funciona y quÃ© decisiones toma?",
    "respuesta_rag": "SegÃºn el texto, los elementos clave que deben estar presentes en un sistema de IA para garantizar su transparencia son:\n\n1. Explicabilidad: capacidad de recontruir cÃ³mo y por quÃ© un sistema se comporta de determinada manera.\n2. Transparencia: conocimiento sobre quiÃ©nes interactÃºan con el sistema, quiÃ©n responderÃ¡ de sus acciones o decisiones, y quÃ© personas estÃ¡n involucradas en su desarrollo y mantenimiento.\n3. Tratabilidad: capacidad de recontruir los procesos y decisiones tomadas por el sistema.\n4. ComunicaciÃ³n: conocimiento sobre que no se trata de un humano sino de un sistema inteligente y quiÃ©nes responderÃ¡n de sus acciones o decisiones.\n5. DocumentaciÃ³n: documentaciÃ³n de los conjuntos de datos, procesos y modelos de negocio que dan lugar a la decisiÃ³n del sistema.\n\nAdemÃ¡s, es importante mencionar que la diversidad en el equipo de desarrollo y la no dependencia de datos histÃ³ricos sesgados tambiÃ©n son fundamentales para garantizar la transparencia y equidad en el uso de algoritmos.",
    "respuestas_adicionales": [
      "La transparencia en la IA implica no solo explicar el proceso por el cual se llega a una conclusiÃ³n, sino tambiÃ©n proporcionar informaciÃ³n sobre los datos utilizados, las fuentes de informaciÃ³n y los algoritmos empleados.",
      "La transparencia es especialmente importante en sistemas de IA que toman decisiones crÃ­ticas o afectan directamente a la vida de las personas, como pueden ser sistemas de evaluaciÃ³n de riesgos o sistemas de recomendaciÃ³n de tratamientos mÃ©dicos.",
      "La transparencia no solo beneficia a los usuarios finales, sino tambiÃ©n puede ayudar a mejorar la confianza en la IA y reducir el riesgo de errores o discriminaciÃ³n."
    ],
    "razonamiento_chain_of_thought": "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”¹ RESPUESTA PRINCIPAL:\nPara que un sistema de IA sea considerado transparente, es fundamental garantizar la claridad y comprensiÃ³n en el proceso de toma de decisiones. Esto se logra mediante la implementaciÃ³n de mecanismos que permitan entender cÃ³mo se generaron las conclusiones y quÃ© informaciÃ³n fue utilizada para tomarlas. Algunos elementos clave para asegurar la transparencia incluyen:\n\n* La explicabilidad: capacidad del sistema para proporcionar razones y justificaciones detrÃ¡s de sus decisiones.\n* La interpretabilidad: capacidad del sistema para ser comprendido por los usuarios, lo que implica la claridad en el lenguaje utilizado y la facilidad para comprender el proceso de toma de decisiones.\n* La auditable: capacidad del sistema para dejar un rastro de actividad que permita revisar y verificar las decisiones tomadas.\n\nLa transparencia es crucial para construir confianza en los sistemas de IA, ya que permite a los usuarios entender cÃ³mo se generan las conclusiones y quÃ© informaciÃ³n fue utilizada para tomarlas.\n\nğŸ”¸ INFORMACIÃ“N ADICIONAL:\nâ€¢ Â¿QuÃ© caracterÃ­sticas deben poseer los datos utilizados por el sistema de IA para garantizar la transparencia? La respuesta es: los datos deben ser precisos, actualizados y representativos del conjunto de datos original. Esto permite que el sistema de IA genere conclusiones basadas en informaciÃ³n fiable y relevante.\nâ€¢ Â¿QuÃ© papel juega la Ã©tica en la transparencia de un sistema de IA? La respuesta es: la Ã©tica es fundamental para garantizar la transparencia, ya que implica considerar los valores y principios morales detrÃ¡s de las decisiones tomadas por el sistema. Esto permite que el sistema de IA genere conclusiones que sean justas y equitativas.\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€",
    "timestamp": "2025-07-18T13:05:57.375048",
    "contexto": [
      "desafÃ­os, implementando medidas que garanticen la transparencia, la responsabilidad y la equidad en el uso \nde algoritmos. Solo asÃ­ se podrÃ¡ aprovechar plenamente el potencial de la inteligencia artificial en la gober-\nnanza pÃºblica, garantizando al mismo tiempo que se respeten los principios fundamentales de la democra-\ncia y los derechos humanos. Se aÃ±ade que la creciente incorporaciÃ³n de sistemas algorÃ­tmicos en la toma \nde decisiones gubernamentales y comerciales ha traÃ­do consigo el reto de garantizar la transparencia y \nequidad de estas tecnologÃ­as. La necesidad de una gobernanza algorÃ­tmica centrada en la Ã©tica ha subraya-\ndo la importancia de mecanismos de auditorÃ­a para identificar y corregir posibles sesgos presentes en los \nmodelos algorÃ­tmicos. Este enfoque no solo mejora la equidad en la toma de decisiones, sino que tambiÃ©n \npromueve la confianza pÃºblica en estas tecnologÃ­as. Es cierto que uno de los principales desafÃ­os polÃ­ticos",
      "Transparencia y explicabilidad para prevenir la discriminaciÃ³n 73\nAdemÃ¡s de la explicabilidad, la transparencia incluye tambiÃ©n la traza-\nbilidad y la comunicaciÃ³n 66. Esto significa que no sÃ³lo se debe poder recons -\ntruir cÃ³mo y por quÃ© un sistema se comporta de determinada manera, sino \nque quienes interactÃºen con ellos deben saber que no se trata de un humano \nsino de un sistema inteligente y quÃ© personas responderÃ¡n de sus acciones o \ndecisiones. \nA mayor abundamiento, la transparencia tambiÃ©n debe aplicarse a los \nelementos del sistema de IA, es decir, los datos, el software y los modelos de \nnegocio 67. Para conseguirla, deben documentarse los conjuntos de datos y \nprocesos que dan lugar a la decisiÃ³n del sistema, incluidos los relativos a la \nrecopilaciÃ³n y etiquetado de datos, estar disponibles las explicaciones sobre \nel grado en que un sistema de IA condiciona e influye en el proceso de toma \nde decisiones de la organizaciÃ³n, las opciones de diseÃ±o de dicho sistema y la",
      "mundo, la falta de diversidad en los equipos de desarrollo y la dependencia de datos histÃ³ricos sesgados \nhan contribuido a la perpetuaciÃ³n de desigualdades a travÃ©s de la tecnologÃ­a.\nOtro desafÃ­o importante es la falta de transparencia en los sistemas algorÃ­tmicos. Muchos de estos siste-\nmas operan como \"cajas negras\", lo que significa que su funcionamiento interno no es comprensible para los \nusuarios o incluso para los propios desarrolladores. Esto plantea serios problemas de responsabilidad, ya \nque es difÃ­cil determinar quiÃ©n es responsable cuando un algoritmo toma una decisiÃ³n errÃ³nea o injusta \n(Groves et al., 2024). La opacidad de estos sistemas tambiÃ©n dificulta la implementaciÃ³n de mecanismos de \ncontrol y supervisiÃ³n, lo que aumenta el riesgo de abuso. Por ello, la transparencia es un principio fundamen-\ntal en la gobernanza pÃºblica, y su importancia se amplifica en el contexto de la gestiÃ³n algorÃ­tmica. La capa-",
      "promueve la confianza pÃºblica en estas tecnologÃ­as. Es cierto que uno de los principales desafÃ­os polÃ­ticos \nen la implementaciÃ³n de algoritmos en la gobernanza es la opacidad inherente a muchos de estos sistemas, \nlo que dificulta la identificaciÃ³n de sesgos y errores. La transparencia algorÃ­tmica implica hacer visibles los \nprocesos y las decisiones tomadas por los algoritmos, permitiendo su anÃ¡lisis y auditorÃ­a. SegÃºn Giunchiglia \net al. (2021), la diversidad es un factor clave para impulsar la transparencia, ya que permite comprender mejor \ny abordar los sesgos que pueden surgir en los sistemas algorÃ­tmicos. AdemÃ¡s, la transparencia tambiÃ©n se \nve como un prerrequisito para construir confianza y legitimidad en los sistemas algorÃ­tmicos, especialmente \ncuando afectan derechos humanos fundamentales como la privacidad y la no discriminaciÃ³n. La auditorÃ­a de \nsesgos se ha convertido en una prÃ¡ctica esencial para garantizar que los algoritmos no perpetÃºen o amplifi-"
    ],
    "fuentes": [
      {
        "documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf",
        "pagina": 4
      },
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 48
      },
      {
        "documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf",
        "pagina": 3
      },
      {
        "documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf",
        "pagina": 4
      }
    ]
  }
]\n4. **Data protection**: A human rights approach would prioritize the protection of personal data and privacy, particularly in light of the potential risks associated with AI-generated intelligence.\n\nBy adopting a human rights perspective, policymakers can ensure that the development and governance of AI align with fundamental principles of dignity, equality, and justice for all individuals.",
    "contexto": [
      "Documento: 6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf, PÃ¡gina: 3",
      "Documento: 6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf, PÃ¡gina: 89",
      "Documento: 6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf, PÃ¡gina: 94",
      "Documento: 6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf, PÃ¡gina: 1"
    ]
  },
  {
    "pregunta": "Â¿CÃ³mo se define la opacidad algorÃ­tmica en este documento y quÃ© consecuencias conlleva?",
    "respuesta_rag": "According to the document, \"opacidad\" (algorithmic opacity) refers to the complexity and lack of transparency in AI systems. It is mentioned that this characteristic makes it difficult to determine when, how, or why an error occurred in a system and who should be held accountable for any damages caused.\n\nIn particular, the document states that the opaqueness of algorithms is considered a major challenge in detecting and demonstrating algorithmic discrimination. This opacity is seen as a key issue in understanding how AI systems work and making them more transparent and accountable.\n\nThe consequences of algorithmic opacity are not explicitly stated in this specific section, but it can be inferred that it contributes to the difficulties in identifying and addressing biases and discriminatory outcomes in AI decision-making processes.",
    "contexto": [
      "Documento: 6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf, PÃ¡gina: 30",
      "Documento: 7. IA y Transparencia AlgorÃ­tmica â€“ G. Vestri.pdf, PÃ¡gina: 16",
      "Documento: 6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf, PÃ¡gina: 43",
      "Documento: 7. IA y Transparencia AlgorÃ­tmica â€“ G. Vestri.pdf, PÃ¡gina: 19"
    ]
  },
  {
    "pregunta": "Â¿QuÃ© elementos deben garantizarse para que un sistema de IA sea considerado transparente?",
    "respuesta_rag": "According to the provided context, an AI project should ensure transparency in two aspects:\n\n1. **Process transparency**: The process by which the model is designed and implemented should be transparent.\n2. **Decision and behavior transparency**: The decisions and behaviors of the AI system should be interpretable.\n\nThis means that the AI project should provide clear explanations about how the AI system works, including its decision-making processes, logic, and calculations. This would enable users to understand why the AI system is making certain decisions or behaving in a particular way.",
    "contexto": [
      "Documento: 1. Framework for the Ethical Use of Advanced Data Science.pdf, PÃ¡gina: 16",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 24",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 24",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 13"
    ]
  },
  {
    "pregunta": "Â¿QuÃ© riesgos plantea el uso de IA desde la perspectiva del derecho de daÃ±os?",
    "respuesta_rag": "Based on the provided context, it can be inferred that the use of AI poses risks in terms of determining the locus of responsibility for accidents or injuries caused by autonomous systems. This is a concern that needs to be addressed through clarification of legal issues and consideration of insurance options.\n\nIn the context of tort law, some potential risks posed by the use of AI include:\n\n1. Unclear locus of responsibility: As mentioned earlier, one of the main concerns is determining who is responsible for accidents or injuries caused by autonomous systems. This could lead to disputes and difficulties in assigning liability.\n2. Lack of human involvement: Autonomous systems may operate without direct human intervention, making it challenging to determine whether a human or AI system was at fault in case of an accident.\n3. Insufficient data and evidence: In cases where AI systems are involved, there may be limited data and evidence available to establish the cause of an accident or injury.\n4. New forms of liability: The use of AI could give rise to new forms of liability that are not yet fully understood or addressed by existing laws.\n\nTo mitigate these risks, it is essential to clarify legal issues related to AI technology utilization, including determining the locus of responsibility for accidents and injuries, as well as developing insurance options to cover potential risks.",
    "contexto": [
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 19",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 6",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 9",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 20"
    ]
  },
  {
    "pregunta": "Â¿QuÃ© tipos de responsabilidad jurÃ­dica se podrÃ­an aplicar en casos de perjuicios causados por sistemas de IA?",
    "respuesta_rag": "Based on the provided context, it seems that there are several types of legal liability that could be applied in cases where AI systems cause harm:\n\n1. Determining the locus of responsibility: Clarifying who is responsible for accidents or damages caused by autonomous car systems or other AI technologies.\n2. Insurance: Utilizing insurance to prepare for probabilistic risks and provide compensation for damages or injuries caused by AI systems.\n3. Rights infringement: Considering the rights to and incentives for the creation of AI technologies, including assignment of rights (incentives) to algorithm developers, users, and data providers through contracts and guidelines.\n\nAdditionally, it is mentioned that there may be a need to fundamentally reconsider underlying legal concepts, such as human responsibility, in light of the increasing use of AI technologies.",
    "contexto": [
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 19",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 6",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 20",
      "Documento: 3. AI and Human Society â€“ JapÃ³n\n.pdf, PÃ¡gina: 19"
    ]
  },
  {
    "pregunta": "Â¿QuÃ© propone el documento para mitigar los sesgos algorÃ­tmicos en sistemas de decisiÃ³n automatizada?",
    "razonamiento_interno": "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”¹ RESPUESTA PRINCIPAL:\nEl documento propone varias estrategias para mitigar los sesgos algorÃ­tmicos en sistemas de decisiÃ³n automatizados, incluyendo la implementaciÃ³n de mecanismos de auditorÃ­a y revisiÃ³n manual, el uso de datos mÃ¡s representativos y diversificados, la aplicaciÃ³n de tÃ©cnicas de normalizaciÃ³n y standardizaciÃ³n, y la incorporaciÃ³n de mÃ©tricas de equidad y justicia en los algoritmos.\n\nğŸ”¸ INFORMACIÃ“N ADICIONAL:\nâ€¢ Â¿QuÃ© entendemos por sesgos algorÃ­tmicos? Un sesgo algorÃ­tmico se refiere a la tendencia inherente en un sistema automatizado para producir resultados no equitativos o discriminatorios debido a la presencia de datos sesgados, parcialidad en el diseÃ±o del modelo o errores en la implementaciÃ³n. Es importante identificar y comprender los sesgos algorÃ­tmicos para desarrollar estrategias efectivas para mitigarlos.\nâ€¢ Â¿QuÃ© papel juega la diversificaciÃ³n de datos en la reducciÃ³n de sesgos algorÃ­tmicos? La diversificaciÃ³n de datos es fundamental para minimizar los sesgos algorÃ­tmicos, ya que permite capturar mejor las variaciones y patrones presentes en el conjunto de datos. Esto puede lograrse mediante la inclusiÃ³n de datos mÃ¡s representativos y diversificados, lo que a su vez puede involucrar la recopilaciÃ³n de nuevos datos o la creaciÃ³n de conjuntos de datos artificiales mÃ¡s equitativos.",
    "respuesta_rag": "El documento no explicita directamente una propuesta para mitigar los sesgos algorÃ­tmicos en sistemas de decisiÃ³n automatizada. Sin embargo, se puede inferir que la transparencia y el derecho a informaciÃ³n del interesado pueden ser herramientas importantes para mitigar este riesgo.\n\nEn particular, se menciona la importancia de informar sobre la lÃ³gica aplicada, la ponderaciÃ³n relativa de cada variable en el modelo y cualquier cambio de estos parÃ¡metros que modifique el comportamiento del algoritmo (apartado 4.2.2). Esto sugiere que la transparencia en la toma de decisiones automatizadas puede ser un mecanismo para detectar y mitigar posibles sesgos.\n\nAdemÃ¡s, se menciona el artÃ­culo 22 del RGPD, que establece que el responsable del tratamiento adoptarÃ¡ medidas para minimizar el impacto en el fondo o resultado de la toma de decisiones, lo que sugiere que la implementaciÃ³n de mecanismos de control y verificaciÃ³n puede ser una forma de mitigar los sesgos algorÃ­tmicos.\n\nEn resumen, aunque no se propone directamente una soluciÃ³n para mitigar los sesgos algorÃ­tmicos, el documento destaca la importancia de la transparencia y la informaciÃ³n en la toma de decisiones automatizadas como un posible mecanismo para detectar y mitigar este riesgo.",
    "timestamp": "2025-07-18T10:41:29.033452",
    "contexto": [
      "autor Â«es reconfortante observar un progresivo reconocimiento normativo de la importancia de las \ngarantÃ­as en decisiones parcial o semi-automatizadasÂ», teniendo en cuenta que tanto la Carta de \nDerechos Digitales en EspaÃ±a, como algunas legislaciones de protecciÃ³n de datos fuera de la UE \ntambiÃ©n las recogen expresamente, como por ejemplo, la de Ecuador. TambiÃ©n en CanadÃ¡ o EEUU \nla definiciÃ³n de sistema de decisiones automatizado (automated decision system) incluye tanto las deci-\nsiones totalmente automatizadas como las de apoyo a la decisiÃ³n. Vid., por ejemplo, el proyecto de \nLey de Responsabilidad AlgorÃ­tmica de 2022 de EEUU (secciÃ³n 2; Definiciones).\n115 Las entidades de informaciÃ³n y anÃ¡lisis de riesgo (como SCHUFA o en el caso del mercado \nespaÃ±ol, Equifax o Experian) analizan el riesgo de un prestatario, combinando factores objetivos \ny subjetivos a partir de la informaciÃ³n de que disponen sobre el prestatario, y/o de la informaciÃ³n",
      "ca cuando el interesado es objeto de una decisiÃ³n plenamente automatizada \nbasada en sus datos personales y con efectos jurÃ­dicos o similares en Ã©l: por un \nlado, los arts.13.2 f), 14.2 g) y 15.1.h) obligan a informarle sobre la existencia \nde decisiones automatizadas,  incluida la elaboraciÃ³n de perfiles, y al menos en \ntales casos, a darle informaciÃ³n significativa sobre la lÃ³gica aplicada, asÃ­ como la \nimportancia y las consecuencias que dicho tratamiento puede tener para su persona . \nPor tanto, se consagra un derecho de informaciÃ³n reforzado o ampliado exi -\ngible cuando concurren los presupuestos mencionados; por otro lado, el art. \n22.3 establece que, en tales casos, el responsable del tratamiento adoptarÃ¡ las \n79 Dichos principios son: licitud, lealtad y transparencia (art. 5.1.a); limitaciÃ³n de la finalidad \n(art.5.1.b); minimizaciÃ³n de datos (art. 5.1.c); exactitud (art. 5.1.d); limitaciÃ³n del plazo de conser -",
      "no afecten al fondo, ni por consiguiente al resultado, de la toma de decisiones \nhumana o automatizada. Las condiciones (una o varias) para que pueda con-\nsiderarse que un sistema no plantea dicho riesgo al no influir sustancialmente \nen el resultado de la toma de decisiones, se recogen en el art. 6.3. Su concu -\nrrencia implicarÃ¡ que esos sistemas no queden sometidos a los requisitos que \nel RIA impone a los sistemas de alto riesgo.\nRespecto a los principales elementos de la decisiÃ³n adoptada, creemos que po-\ndrÃ­a aplicarse aquÃ­ lo explicado en el apartado 4.2.2 sobre el contenido del de-\nrecho de informaciÃ³n reforzado en el RGPD. AsÃ­, habrÃ­a que informar, entre \notras cosas, de los factores utilizados por el algoritmo para tomar la decisiÃ³n \no la elaboraciÃ³n del perfil, la ponderaciÃ³n relativa de cada variable en el mo-\ndelo para la toma de la decisiÃ³n y cualquier cambio de estos parÃ¡metros que \nmodifique el comportamiento del algoritmo, las reglas e instrucciones utiliza-",
      "sentido, las cuestiones examinadas parecen orientarse a la determinaciÃ³n de \nsi se ha utilizado el algoritmo para el tratamiento de los datos con miras a la \ndecisiÃ³n; el nivel de importancia que tuvo el tratamiento automatizado en el \nprocedimiento y el funcionamiento del algoritmo o quÃ© consecuencias pueden \nderivar del proceso automatizado para la persona en cuestiÃ³n.\nDe interÃ©s es tambiÃ©n el artÃ­culo 15 del RGPD â€”Derecho de acceso del \ninteresadoâ€” que seÃ±ala: Â«El interesado tendrÃ¡ derecho a obtener del responsa-\nble del tratamiento confirmaciÃ³n de si se estÃ¡n tratando o no datos personales \nque le conciernen y, en tal caso, derecho de acceso a los datos personales y \na la siguiente informaciÃ³n: [...] h) la existencia de decisiones automatizadas, \nincluida la elaboraciÃ³n de perfiles, a que se refiere el artÃ­culo 22, apartados \n1 y 4, y, al menos en tales casos, informaciÃ³n significativa sobre la lÃ³gica \naplicada, asÃ­ como la importancia y las consecuencias previstas de dicho"
    ],
    "fuentes": [
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 66
      },
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 53
      },
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 85
      },
      {
        "documento": "7. IA y Transparencia AlgorÃ­tmica â€“ G. Vestri.pdf",
        "pagina": 20
      }
    ]
  },
  {
    "pregunta": "Â¿QuÃ© propone el documento para mitigar los sesgos algorÃ­tmicos en sistemas de decisiÃ³n automatizada?",
    "pregunta_refinada": "Â¿CÃ³mo abordan los autores del documento las posibles fuentes de sesgo algorÃ­tmico en sistemas de toma de decisiones automatizadas y quÃ© estrategias o recomendaciones presentan para reducir o eliminar estos sesgos y mejorar la objetividad en la toma de decisiones?",
    "respuesta_rag": "Los autores del documento no abordan especÃ­ficamente las posibles fuentes de sesgo algorÃ­tmico en sistemas de toma de decisiones automatizadas. Sin embargo, se refieren a la importancia de la transparencia y el acceso a la informaciÃ³n sobre la lÃ³gica aplicada por los algoritmos en la toma de decisiones.\n\nEn cuanto a estrategias o recomendaciones para reducir o eliminar estos sesgos y mejorar la objetividad en la toma de decisiones, no se presentan especÃ­ficas en el documento. Sin embargo, se menciona la importancia de informar sobre los factores utilizados por el algoritmo para tomar la decisiÃ³n, la ponderaciÃ³n relativa de cada variable en el modelo y cualquier cambio de estos parÃ¡metros que modifique el comportamiento del algoritmo.\n\nEn general, las estrategias para reducir o eliminar sesgos algorÃ­tmicos incluyen:\n\n1. Transparencia: proporcionar informaciÃ³n sobre la lÃ³gica aplicada por los algoritmos en la toma de decisiones.\n2. Acceso a la informaciÃ³n: permitir el acceso a los datos y algoritmos utilizados para tomar las decisiones.\n3. EvaluaciÃ³n y ajuste: evaluar y ajustar regularmente los algoritmos para minimizar el sesgo y mejorar la objetividad.\n4. Diversidad en la construcciÃ³n de conjuntos de entrenamiento: utilizar conjuntos de entrenamiento diversificados para reducir el sesgo y mejorar la generalizaciÃ³n.\n5. Monitoreo y evaluaciÃ³n: monitorear y evaluar regularmente los algoritmos para detectar y corregir cualquier sesgo o error.\n\nEs importante destacar que la eliminaciÃ³n completa del sesgo es un objetivo difÃ­cil de alcanzar, ya que los algoritmos pueden reflejar las limitaciones y sesgos inherentes en los datos y en el proceso de construcciÃ³n de los modelos. Sin embargo, la transparencia, el acceso a la informaciÃ³n y la evaluaciÃ³n regular pueden ayudar a minimizar el impacto del sesgo y mejorar la objetividad en la toma de decisiones.",
    "timestamp": "2025-07-18T11:19:00.024748",
    "contexto": [
      "ca cuando el interesado es objeto de una decisiÃ³n plenamente automatizada \nbasada en sus datos personales y con efectos jurÃ­dicos o similares en Ã©l: por un \nlado, los arts.13.2 f), 14.2 g) y 15.1.h) obligan a informarle sobre la existencia \nde decisiones automatizadas,  incluida la elaboraciÃ³n de perfiles, y al menos en \ntales casos, a darle informaciÃ³n significativa sobre la lÃ³gica aplicada, asÃ­ como la \nimportancia y las consecuencias que dicho tratamiento puede tener para su persona . \nPor tanto, se consagra un derecho de informaciÃ³n reforzado o ampliado exi -\ngible cuando concurren los presupuestos mencionados; por otro lado, el art. \n22.3 establece que, en tales casos, el responsable del tratamiento adoptarÃ¡ las \n79 Dichos principios son: licitud, lealtad y transparencia (art. 5.1.a); limitaciÃ³n de la finalidad \n(art.5.1.b); minimizaciÃ³n de datos (art. 5.1.c); exactitud (art. 5.1.d); limitaciÃ³n del plazo de conser -",
      "no afecten al fondo, ni por consiguiente al resultado, de la toma de decisiones \nhumana o automatizada. Las condiciones (una o varias) para que pueda con-\nsiderarse que un sistema no plantea dicho riesgo al no influir sustancialmente \nen el resultado de la toma de decisiones, se recogen en el art. 6.3. Su concu -\nrrencia implicarÃ¡ que esos sistemas no queden sometidos a los requisitos que \nel RIA impone a los sistemas de alto riesgo.\nRespecto a los principales elementos de la decisiÃ³n adoptada, creemos que po-\ndrÃ­a aplicarse aquÃ­ lo explicado en el apartado 4.2.2 sobre el contenido del de-\nrecho de informaciÃ³n reforzado en el RGPD. AsÃ­, habrÃ­a que informar, entre \notras cosas, de los factores utilizados por el algoritmo para tomar la decisiÃ³n \no la elaboraciÃ³n del perfil, la ponderaciÃ³n relativa de cada variable en el mo-\ndelo para la toma de la decisiÃ³n y cualquier cambio de estos parÃ¡metros que \nmodifique el comportamiento del algoritmo, las reglas e instrucciones utiliza-",
      "sentido, las cuestiones examinadas parecen orientarse a la determinaciÃ³n de \nsi se ha utilizado el algoritmo para el tratamiento de los datos con miras a la \ndecisiÃ³n; el nivel de importancia que tuvo el tratamiento automatizado en el \nprocedimiento y el funcionamiento del algoritmo o quÃ© consecuencias pueden \nderivar del proceso automatizado para la persona en cuestiÃ³n.\nDe interÃ©s es tambiÃ©n el artÃ­culo 15 del RGPD â€”Derecho de acceso del \ninteresadoâ€” que seÃ±ala: Â«El interesado tendrÃ¡ derecho a obtener del responsa-\nble del tratamiento confirmaciÃ³n de si se estÃ¡n tratando o no datos personales \nque le conciernen y, en tal caso, derecho de acceso a los datos personales y \na la siguiente informaciÃ³n: [...] h) la existencia de decisiones automatizadas, \nincluida la elaboraciÃ³n de perfiles, a que se refiere el artÃ­culo 22, apartados \n1 y 4, y, al menos en tales casos, informaciÃ³n significativa sobre la lÃ³gica \naplicada, asÃ­ como la importancia y las consecuencias previstas de dicho",
      "autor Â«es reconfortante observar un progresivo reconocimiento normativo de la importancia de las \ngarantÃ­as en decisiones parcial o semi-automatizadasÂ», teniendo en cuenta que tanto la Carta de \nDerechos Digitales en EspaÃ±a, como algunas legislaciones de protecciÃ³n de datos fuera de la UE \ntambiÃ©n las recogen expresamente, como por ejemplo, la de Ecuador. TambiÃ©n en CanadÃ¡ o EEUU \nla definiciÃ³n de sistema de decisiones automatizado (automated decision system) incluye tanto las deci-\nsiones totalmente automatizadas como las de apoyo a la decisiÃ³n. Vid., por ejemplo, el proyecto de \nLey de Responsabilidad AlgorÃ­tmica de 2022 de EEUU (secciÃ³n 2; Definiciones).\n115 Las entidades de informaciÃ³n y anÃ¡lisis de riesgo (como SCHUFA o en el caso del mercado \nespaÃ±ol, Equifax o Experian) analizan el riesgo de un prestatario, combinando factores objetivos \ny subjetivos a partir de la informaciÃ³n de que disponen sobre el prestatario, y/o de la informaciÃ³n"
    ],
    "fuentes": [
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 53
      },
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 85
      },
      {
        "documento": "7. IA y Transparencia AlgorÃ­tmica â€“ G. Vestri.pdf",
        "pagina": 20
      },
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 66
      }
    ]
  },
  {
    "pregunta": "Â¿QuÃ© elementos deben garantizarse para que un sistema de IA sea considerado transparente?",
    "pregunta_refinada": "Â¿CuÃ¡les son los requisitos especÃ­ficos y caracterÃ­sticas clave que debieran cumplirse para que un sistema de Inteligencia Artificial (IA) sea considerado transparente en tÃ©rminos de explicabilidad, justificabilidad y accesibilidad de sus decisiones y procesos?",
    "respuesta_rag": "SegÃºn el texto, los requisitos especÃ­ficos y caracterÃ­sticas clave que debieran cumplirse para que un sistema de Inteligencia Artificial (IA) sea considerado transparente en tÃ©rminos de explicabilidad, justificabilidad y accesibilidad de sus decisiones y procesos son:\n\n1. Auditable: Los algoritmos deben ser audibles, es decir, debe ser posible revisar y analizar el proceso de toma de decisiones.\n2. Transparent: Los sistemas de IA deben ser transparentes, lo que significa que los resultados y procesos deben ser claros y fÃ¡ciles de entender.\n3. Explicables: Los algoritmos deben ser explicables, es decir, debe ser posible comprender cÃ³mo llegaron a ciertas conclusiones o decisiones.\n\nAdemÃ¡s, se menciona la necesidad de equilibrio entre la mejora de la explicabilidad del sistema (que puede reducir su precisiÃ³n) y una mayor precisiÃ³n del mismo (a costa de la explicabilidad).\n\nEn resumen, para que un sistema de IA sea considerado transparente, debe ser auditable, transparente y explicable, y debe equilibrar la explicabilidad con la precisiÃ³n.",
    "timestamp": "2025-07-18T11:28:32.503900",
    "contexto": [
      "que implica y su concreta efectividad cuando la automatizaciÃ³n de decisiones \nse lleva a cabo a travÃ©s de sistemas de IA, han sido objeto de crÃ­ticas y comen-\n85 NÃšÃ‘EZ SEOANE, J., op.cit., p. 308\n86 HERRERA DE LAS HERAS, R., Â«ProtecciÃ³n de datos e inteligencia artificialÂ», en Cruz \nBlanca/LledÃ³ Benito (coords.), La robÃ³tica y la inteligencia artificial en la nueva era de la revoluciÃ³n indus-\ntrial 4.0, 2021, p. 654. No obstante, como matiza REBOLLO DELGADO, L. Inteligencia artificial y dere-\nchos fundamentales, Madrid, 2023, p. 107, estas dos funcionalidades hoy en dÃ­a ya no son troncales de \nla IA y la aplicaciÃ³n del precepto Ãºnicamente a ellas se manifiesta claramente insuficiente teniendo \nen cuenta la amplitud de posibilidades que ofrece la IA. Para una explicaciÃ³n detallada sobre las dife-\nrencias entre estas dos figuras jurÃ­dicas recogidas en el RGPD que guardan relaciÃ³n con los procesos",
      "mas algorÃ­tmicos.\nEl rol del usuario en la interpretaciÃ³n de los resultados generados por el sistema de inteligencia artificial \nes crucial. Dependiendo del contexto, el usuario puede actuar como mero receptor de informaciÃ³n o como \nun evaluador crÃ­tico que valida los resultados antes de su aplicaciÃ³n. Por ejemplo, en el Ã¡mbito de la justicia, \nun algoritmo de predicciÃ³n de reincidencia debe ser utilizado como una herramienta de apoyo y no como \nuna decisiÃ³n definitiva sin supervisiÃ³n humana. En contraste, en tareas mÃ¡s operativas, como la clasificaciÃ³n \nautomÃ¡tica de correos electrÃ³nicos, la intervenciÃ³n humana puede no ser necesaria. Para ilustrar esto, con-\nsideremos un sistema de diagnÃ³stico mÃ©dico asistido por IA: si bien el algoritmo puede generar una proba-\nbilidad de enfermedad basada en los sÃ­ntomas del paciente, la decisiÃ³n final debe estar a cargo de un pro -\nfesional de la salud que contextualice la informaciÃ³n.",
      "Artificial, tecnologÃ­as emergentes y Derecho,2021, p.187, consideran que los algoritmos deben ser audita -\nbles, transparentes, y explicables y si se logra implementar algoritmos con tales caracterÃ­sticas segura-\nmente las decisiones que se obtengan podrÃ¡n ser mÃ¡s transparentes que las decisiones humanas bien \nintencionadas, pero inconscientemente sesgadas.",
      "IA que permite al observador humano comprender o entender el sistema, mientras que habrÃ­a otros \nsistemas de IA que no son transparentes, pero pueden llegar a ser explicables mediante distintas \ntÃ©cnicas a partir del comportamiento del modelo, los datos utilizados, los resultados obtenidos y del \nproceso completo de la toma de decisiÃ³nÂ». \n35 Esta necesidad de encontrar un equilibrio entre la mejora de la explicabilidad de un siste -\nma (que puede reducir su precisiÃ³n) o una mayor precisiÃ³n del mismo (a costa de la explicabilidad), \nya se ponÃ­a de relieve en las Directrices Ã©ticas del Grupo de Expertos. En dicho documento se establecÃ­a \nla necesidad de que cuando un sistema de IA tuviera un impacto significativo en la vida de las perso-\nnas, deberÃ­a ser posible reclamar una explicaciÃ³n adecuada del proceso de toma de decisiones del \nsistema de IA (vid., ap. 77).\n36 Se ha mantenido que los algoritmos podrÃ­an quedar protegidos por la Ley 1/2019, de 20"
    ],
    "fuentes": [
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 56
      },
      {
        "documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf",
        "pagina": 5
      },
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 31
      },
      {
        "documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf",
        "pagina": 37
      }
    ]
  }
]{"pregunta": "Â¿QuÃ© elementos deben garantizarse para que un sistema de IA sea considerado transparente?", "razonamiento_interno": "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”¹ RESPUESTA PRINCIPAL:\nPara que un sistema de IA sea considerado transparente, es fundamental garantizar la claridad y comprensiÃ³n en el proceso de toma de decisiones. Esto se logra mediante la implementaciÃ³n de mecanismos que permitan entender cÃ³mo se generaron los resultados, como por ejemplo:\n\n* La explicabilidad de las decisiones: Los sistemas deben ser capaces de proporcionar razones y justificaciones para sus acciones.\n* El acceso a informaciÃ³n relevante: Los usuarios deben tener acceso a la informaciÃ³n utilizada para tomar decisiones, lo que les permite comprender el proceso detrÃ¡s los resultados.\n\nğŸ”¸ INFORMACIÃ“N ADICIONAL:\nâ€¢ Â¿QuÃ© caracterÃ­sticas debe tener un sistema de IA para ser considerado transparente? Auto-pregunta: Â¿CuÃ¡les son las condiciones necesarias para que un sistema de IA sea considerado transparente?\n\t+ Respuesta breve, precisa y relevante: La transparencia en un sistema de IA se logra cuando se cumplen tres condiciones: la explicabilidad de las decisiones, el acceso a informaciÃ³n relevante y la capacidad de comprender cÃ³mo se generaron los resultados.\nâ€¢ Â¿CuÃ¡les son los beneficios de una IA transparente? Auto-pregunta: Â¿QuÃ© ventajas ofrece una IA que es capaz de proporcionar transparencia en sus procesos?\n\t+ Respuesta breve, precisa y relevante: La transparencia en un sistema de IA puede llevar a una mayor confianza y aceptaciÃ³n por parte de los usuarios, lo que a su vez puede generar beneficios como la mejora de la toma de decisiones, la reducciÃ³n del riesgo y la creaciÃ³n de oportunidades para el aprendizaje y el mejoramiento.", "respuesta_rag": "SegÃºn el texto, algunos de los elementos que deben garantizarse para que un sistema de IA sea considerado transparente son:\n\n* Auditable: Los algoritmos deben ser audibles, lo que permite identificar y corregir posibles sesgos presentes en los modelos algorÃ­tmicos.\n* Transparentes: Los procesos y las decisiones tomadas por los algoritmos deben ser visibles, permitiendo su anÃ¡lisis y auditorÃ­a.\n* Explicables: Los algoritmos deben ser explicables, lo que permite comprender mejor y abordar los sesgos que pueden surgir en los sistemas algorÃ­tmicos.\n\nAdemÃ¡s, la diversidad es un factor clave para impulsar la transparencia, ya que permite comprender mejor y abordar los sesgos que pueden surgir en los sistemas algorÃ­tmicos.", "timestamp": "2025-07-18T11:43:27.352904", "fuentes": [{"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 5}, {"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 4}, {"documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf", "pagina": 31}, {"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 4}]}
{"pregunta": "Â¿QuÃ© elementos deben garantizarse para que un sistema de IA sea considerado transparente?", "razonamiento_interno": "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”¹ RESPUESTA PRINCIPAL:\nPara que un sistema de IA sea considerado transparente, es fundamental garantizar la claridad y comprensiÃ³n en el proceso de toma de decisiones. Esto se logra mediante la implementaciÃ³n de mecanismos que permitan entender cÃ³mo se generaron las conclusiones y los resultados. Algunos elementos clave para asegurar la transparencia incluyen:\n\n* La explicabilidad: capacidad del sistema para proporcionar razones y justificaciones detrÃ¡s de sus decisiones.\n* El acceso a datos: disponibilidad de los datos utilizados por el sistema, lo que permite evaluar su calidad y relevancia.\n* La reproducibilidad: capacidad del sistema para generar resultados similares cuando se repite el proceso con los mismos datos y condiciones.\n\nğŸ”¸ INFORMACIÃ“N ADICIONAL:\nâ€¢ Â¿QuÃ© caracterÃ­sticas deben tener los algoritmos de aprendizaje automÃ¡tico para ser considerados transparentes? Algunas caracterÃ­sticas clave incluyen la capacidad de proporcionar explicaciones sobre sus decisiones, la utilizaciÃ³n de tÃ©cnicas de interpretaciÃ³n de modelos y la implementaciÃ³n de mecanismos de auditorÃ­a.\nâ€¢ Â¿CÃ³mo se puede garantizar la transparencia en sistemas de IA que involucran datos personales? Para lograr esto, es fundamental implementar medidas de protecciÃ³n de datos, como la anonimizaciÃ³n o el cifrado, y proporcionar informaciÃ³n clara sobre cÃ³mo se utilizan los datos y quÃ© se hace con ellos.", "respuesta_rag": "SegÃºn el texto, para que un sistema de IA sea considerado transparente, se deben garantizar los siguientes elementos:\n\n1. Visibilidad de los procesos y decisiones tomadas por los algoritmos.\n2. AnÃ¡lisis y auditorÃ­a de los sistemas algorÃ­tmicos.\n3. Diversidad en la creaciÃ³n de los modelos algorÃ­tmicos para minimizar sesgos.\n\nEstos elementos permiten comprender mejor y abordar los sesgos que pueden surgir en los sistemas algorÃ­tmicos, lo que es fundamental para construir confianza y legitimidad en estos sistemas, especialmente cuando afectan derechos humanos fundamentales.", "timestamp": "2025-07-18T11:58:43.554245", "fuentes": [{"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 5}, {"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 4}, {"documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf", "pagina": 31}, {"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 4}]}
{"pregunta": "Â¿QuÃ© elementos deben garantizarse para que un sistema de IA sea considerado transparente?", "razonamiento_interno": "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nğŸ”¹ RESPUESTA PRINCIPAL:\nPara que un sistema de IA sea considerado transparente, es fundamental garantizar la claridad y comprensiÃ³n en el proceso de toma de decisiones. Esto se logra mediante la implementaciÃ³n de mecanismos que permitan entender cÃ³mo se han obtenido los resultados y las conclusiones. Algunos elementos clave para asegurar la transparencia incluyen:\n\n* La explicabilidad: capacidad del sistema para proporcionar razones y justificaciones detrÃ¡s de sus decisiones.\n* El acceso a datos: disponibilidad de los datos utilizados por el sistema, lo que permite evaluar su calidad y relevancia.\n* La auditorÃ­a: capacidad de revisiÃ³n y verificaciÃ³n de las decisiones tomadas por el sistema.\n\nğŸ”¸ INFORMACIÃ“N ADICIONAL:\nâ€¢ Â¿QuÃ© caracterÃ­sticas deben tener los algoritmos para ser considerados transparentes? Algunos ejemplos incluyen la utilizaciÃ³n de tÃ©cnicas de explicabilidad, como modelos interpretativos o mÃ©todos de anÃ¡lisis de contribuciÃ³n, que permiten comprender cÃ³mo se han obtenido los resultados.\nâ€¢ Â¿CÃ³mo se puede garantizar la transparencia en sistemas de IA que utilizan datos privados o sensibles? Para lograr esto, es fundamental implementar medidas de protecciÃ³n de datos y cumplir con las normas y regulaciones aplicables, como la GDPR (RegulaciÃ³n General sobre ProtecciÃ³n de Datos) en la UniÃ³n Europea.", "respuesta_rag": "SegÃºn el texto, la transparencia algorÃ­tmica implica hacer visibles los procesos y las decisiones tomadas por los algoritmos, permitiendo su anÃ¡lisis y auditorÃ­a. AdemÃ¡s, se menciona que la diversidad es un factor clave para impulsar la transparencia, ya que permite comprender mejor y abordar los sesgos que pueden surgir en los sistemas algorÃ­tmicos.\n\nEn general, algunos elementos que deben garantizarse para que un sistema de IA sea considerado transparente son:\n\n* Visibilidad de los procesos: Los pasos que sigue el algoritmo para tomar una decisiÃ³n deben ser claros y comprensibles.\n* Explicabilidad: El algoritmo debe ser capaz de explicar las razones detrÃ¡s de sus decisiones.\n* Acceso a la informaciÃ³n: Los datos utilizados por el algoritmo deben estar disponibles y accesibles para su anÃ¡lisis y auditorÃ­a.\n* Diversidad: La inclusiÃ³n de diferentes perspectivas y puntos de vista puede ayudar a identificar y abordar los sesgos.\n\nEs importante destacar que garantizar la transparencia en un sistema de IA no solo es una cuestiÃ³n tÃ©cnica, sino tambiÃ©n Ã©tica. Es necesario involucrar a mÃºltiples actores, incluyendo organizaciones de la sociedad civil y auditores independientes, para asegurarse de que los sistemas se diseÃ±en y operen de manera que minimicen los sesgos y maximicen la equidad y la justicia.", "timestamp": "2025-07-18T12:10:55.760398", "fuentes": [{"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 5}, {"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 4}, {"documento": "6. IA y Derecho de DaÃ±os (Berenguer et al.).pdf", "pagina": 31}, {"documento": "5. Gobernanza algorÃ­tmica y auditorÃ­a de sesgo (Bustelo).pdf", "pagina": 4}]}
